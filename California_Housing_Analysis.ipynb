{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "California Housing Analysis using sparkSQL-pyspark"
      ],
      "metadata": {
        "id": "js3yvhtFAeAo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h8Ke95m7Uqp",
        "outputId": "cc37a3cf-babf-438c-f33d-a2a12a1f7954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=a0251efed41722b7efb22419608112d1c139d8371f8d7ad79009144ef3df7fb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, avg, max, min\n"
      ],
      "metadata": {
        "id": "3JkgASL28apv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"California Housing Analysis\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "6pB3uXsa8asn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load built spark session\n",
        "#asuming that the dataset is available locally in the sample_data directory\n",
        "df_mithil=spark.read.csv(\"sample_data/california_housing_train.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "a79adhx_9JYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mithil.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0ObOkbE9JbG",
        "outputId": "58f0b1ee-9cb6-44ad-f9dc-468ead9cc5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n",
            "|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n",
            "|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Register DataFrame as Temp Table\n",
        "df.createOrReplaceTempView(\"california_housing\")"
      ],
      "metadata": {
        "id": "SG4F4a199Jfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Analysis 1: Calculate average house value by median income bracket\n",
        "result1_mithil = spark.sql(\"\"\"\n",
        "SELECT median_income, AVG(median_house_value) as avg_house_value\n",
        "FROM california_housing\n",
        "GROUP BY median_income\n",
        "ORDER BY median_income\n",
        "\"\"\")\n",
        "result1_mithil.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CulTG-5w9Jiw",
        "outputId": "05f8db27-2494-402d-a991-3007216fcb8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------------------+\n",
            "|median_income|   avg_house_value|\n",
            "+-------------+------------------+\n",
            "|       0.4999|133027.36363636365|\n",
            "|        0.536| 163571.2857142857|\n",
            "|       0.6433|          111300.0|\n",
            "|       0.6775|          350000.0|\n",
            "|       0.6825|          187500.0|\n",
            "|       0.6831|           87500.0|\n",
            "|        0.696|           42500.0|\n",
            "|       0.6991|           89500.0|\n",
            "|       0.7007|          134400.0|\n",
            "|       0.7025|          500001.0|\n",
            "|       0.7068|          200000.0|\n",
            "|       0.7069|           70300.0|\n",
            "|       0.7075|           78800.0|\n",
            "|        0.716|          104200.0|\n",
            "|       0.7286|           95200.0|\n",
            "|       0.7445|          112500.0|\n",
            "|       0.7473|          168800.0|\n",
            "|       0.7526|          162500.0|\n",
            "|       0.7591|          350000.0|\n",
            "|         0.76|          162500.0|\n",
            "+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Analysis 2: Find the maximum and minimum house values in each housing block\n",
        "result2_mithil = spark.sql(\"\"\"\n",
        "SELECT longitude, latitude, MAX(median_house_value) as max_house_value,\n",
        "MIN(median_house_value) as min_house_value\n",
        "FROM california_housing\n",
        "GROUP BY longitude, latitude\n",
        "ORDER BY max_house_value DESC\n",
        "LIMIT 10\n",
        "\"\"\")\n",
        "result2_mithil.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROxgYzFV-U5G",
        "outputId": "acbaa2a3-b76b-430c-9a6a-5c1e139c4929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+---------------+---------------+\n",
            "|longitude|latitude|max_house_value|min_house_value|\n",
            "+---------+--------+---------------+---------------+\n",
            "|  -119.23|   34.19|       500001.0|       500001.0|\n",
            "|   -118.4|   34.13|       500001.0|       500001.0|\n",
            "|  -118.12|   33.76|       500001.0|       461500.0|\n",
            "|  -118.07|   33.72|       500001.0|       485000.0|\n",
            "|  -118.43|   34.02|       500001.0|       500001.0|\n",
            "|  -117.31|   32.82|       500001.0|       500001.0|\n",
            "|  -118.57|   34.27|       500001.0|       500001.0|\n",
            "|  -118.48|   33.96|       500001.0|       500001.0|\n",
            "|  -122.06|    37.3|       500001.0|       500001.0|\n",
            "|  -118.13|   33.79|       500001.0|       234800.0|\n",
            "+---------+--------+---------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ecample analysis 3: determine the average house value for houses older than 50 years\n",
        "result3_mithil=spark.sql(\"\"\"\n",
        "SELECT AVG(median_house_value) as avg_old_house_value\n",
        "    FROM california_housing\n",
        "    WHERE housing_median_age > 50\n",
        "\"\"\")\n",
        "result3_mithil.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2lJaRjg-U8_",
        "outputId": "3d788638-606c-4a22-f0dd-04ff7c16c612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|avg_old_house_value|\n",
            "+-------------------+\n",
            "|  276408.2573800738|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop the Spark Session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "NV108TUl-U_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "rycgXZ6Q-VCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"California Housing Analysis Advance\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "AYAK8Rw0-VG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "lbEC3dOH_O-u",
        "outputId": "12d81817-fa97-45f7-e1a3-b1610e33bde2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f05f8362080>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://056dd4449d2d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>California Housing Analysis Advance</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the California Housing Dataset\n",
        "df = spark.read.csv(\"sample_data/california_housing_train.csv\", header=True, inferSchema=True)\n"
      ],
      "metadata": {
        "id": "IAV2sVJ2_QY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Register DataFrame as Temp Table\n",
        "df.createOrReplaceTempView(\"california_housing\")"
      ],
      "metadata": {
        "id": "qZBN9ZJZ_Qbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Average House Value by Proximity to Ocean (Based on Longitude)\n",
        "result1_mithil = spark.sql(\"\"\"\n",
        "    SELECT CASE\n",
        "    WHEN longitude < -122 THEN 'Near Ocean'\n",
        "    ELSE 'Far from Ocean'\n",
        "     END as proximity_to_ocean,\n",
        "     AVG(median_house_value) as avg_house_value\n",
        "    FROM california_housing\n",
        "    GROUP BY proximity_to_ocean\n",
        "\"\"\")\n",
        "result1_mithil.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT6bI7gu_QeW",
        "outputId": "75472b51-ebd3-4160-e653-7dec9330ecfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------------+\n",
            "|proximity_to_ocean|   avg_house_value|\n",
            "+------------------+------------------+\n",
            "|        Near Ocean|  245589.432132964|\n",
            "|    Far from Ocean|198254.34113882628|\n",
            "+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Average Number of Rooms by Age of Housing\n",
        "result2_mithil = spark.sql(\"\"\"\n",
        "    SELECT housing_median_age,\n",
        "    AVG(total_rooms) as avg_rooms\n",
        "    FROM california_housing\n",
        "    GROUP BY housing_median_age\n",
        "    ORDER BY housing_median_age\n",
        "\"\"\")\n",
        "result2_mithil.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Yjyg0Pf_Qg-",
        "outputId": "05eae606-fbc8-4be2-b992-710a727e8784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------------+\n",
            "|housing_median_age|         avg_rooms|\n",
            "+------------------+------------------+\n",
            "|               1.0|            2158.0|\n",
            "|               2.0| 5237.102040816327|\n",
            "|               3.0| 6920.326086956522|\n",
            "|               4.0| 6065.614906832298|\n",
            "|               5.0| 4926.261306532663|\n",
            "|               6.0| 4365.062015503876|\n",
            "|               7.0| 5672.907284768212|\n",
            "|               8.0|4076.7865168539324|\n",
            "|               9.0|3813.4651162790697|\n",
            "|              10.0|3518.4823008849557|\n",
            "|              11.0| 3971.105769230769|\n",
            "|              12.0| 4216.661458333333|\n",
            "|              13.0|3692.5060240963853|\n",
            "|              14.0| 3720.348703170029|\n",
            "|              15.0|3283.3173076923076|\n",
            "|              16.0| 3047.636220472441|\n",
            "|              17.0|3133.9670138888887|\n",
            "|              18.0|3098.4435146443516|\n",
            "|              19.0| 3005.140776699029|\n",
            "|              20.0|2852.3342036553527|\n",
            "+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Top 10 Locations with the Highest Median Income\n",
        "result3_mithil = spark.sql(\"\"\"\n",
        "    SELECT longitude, latitude, median_income\n",
        "    FROM california_housing\n",
        "    ORDER BY median_income DESC\n",
        "    LIMIT 10\n",
        "\"\"\")\n",
        "result3_mithil.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VetQaSEg_QmW",
        "outputId": "116a34fc-7048-47ac-ef57-4d020a5d6a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-------------+\n",
            "|longitude|latitude|median_income|\n",
            "+---------+--------+-------------+\n",
            "|  -118.04|   34.13|      15.0001|\n",
            "|  -118.34|   34.08|      15.0001|\n",
            "|  -118.06|   33.72|      15.0001|\n",
            "|  -118.19|   34.19|      15.0001|\n",
            "|  -118.33|   34.06|      15.0001|\n",
            "|  -118.32|   34.06|      15.0001|\n",
            "|  -117.23|   32.99|      15.0001|\n",
            "|  -118.33|   34.07|      15.0001|\n",
            "|  -118.18|   34.19|      15.0001|\n",
            "|  -118.12|   34.12|      15.0001|\n",
            "+---------+--------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Relationship Between Population and House Value (Correlation Analysis)\n",
        "result4_mithil = spark.sql(\"\"\"\n",
        "    SELECT POPULATION, median_house_value\n",
        "    FROM california_housing\n",
        "\"\"\")\n",
        "result4_mithil.corr(\"population\", \"median_house_value\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhhRVSf3_Qpn",
        "outputId": "c99a0923-0ee7-4818-f0bb-e449d10ac569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.02785006112089839"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Average House Value by Income Level (Low, Medium, High)\n",
        "result5_mithil = spark.sql(\"\"\"\n",
        "    SELECT CASE\n",
        "    WHEN median_income < 2.5 THEN 'Low Income'\n",
        "    WHEN median_income BETWEEN 2.5 AND 4.5 THEN 'Medium Income'\n",
        "    ELSE 'High Income'\n",
        "           END as income_level,\n",
        "           AVG(median_house_value) as avg_house_value\n",
        "    FROM california_housing\n",
        "    GROUP BY income_level\n",
        "\"\"\")\n",
        "result5_mithil.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8u34Ykf_0Se",
        "outputId": "7315bed3-44e9-46e0-c914-0b66f9738f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------------------+\n",
            "| income_level|   avg_house_value|\n",
            "+-------------+------------------+\n",
            "|  High Income| 306535.0667466027|\n",
            "|   Low Income|120705.26480304956|\n",
            "|Medium Income|187971.56916015383|\n",
            "+-------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Number of Houses in Different Age Groups\n",
        "result6_mithil = spark.sql(\"\"\"\n",
        "    SELECT CASE\n",
        "    WHEN housing_median_age < 20 THEN 'New'\n",
        "    WHEN housing_median_age BETWEEN 20 AND 40 THEN 'Middle-aged'\n",
        "    ELSE 'Old'\n",
        "    END as age_group,\n",
        "    COUNT(*) as house_count\n",
        "    FROM california_housing\n",
        "    GROUP BY age_group\n",
        "    ORDER BY house_count DESC\n",
        "\"\"\")\n",
        "result6_mithil.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_mH4QUc_0Vu",
        "outputId": "773d7634-9910-4e31-d3a2-62f424d74384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "|  age_group|house_count|\n",
            "+-----------+-----------+\n",
            "|Middle-aged|       9004|\n",
            "|        New|       4826|\n",
            "|        Old|       3170|\n",
            "+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Average Number of Bedrooms Per House\n",
        "result7_mithil = spark.sql(\"\"\"\n",
        "    SELECT AVG(total_bedrooms / households) as avg_bedrooms_per_house\n",
        "    FROM california_housing\n",
        "\"\"\")\n",
        "result7_mithil.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-xaMOes_0aH",
        "outputId": "93dc37b2-0fc5-45a4-e6c3-155bd68e76f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+\n",
            "|avg_bedrooms_per_house|\n",
            "+----------------------+\n",
            "|    1.0972809315785848|\n",
            "+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Median House Value by Latitude and Longitude\n",
        "result8_mithil = spark.sql(\"\"\"\n",
        "    SELECT latitude, longitude,\n",
        "           PERCENTILE_APPROX(median_house_value, 0.5) as median_value\n",
        "    FROM california_housing\n",
        "    GROUP BY latitude, longitude\n",
        "    ORDER BY median_value DESC\n",
        "    LIMIT 10\n",
        "\"\"\")\n",
        "result8_mithil.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWO3396wAMJ1",
        "outputId": "8237ec8f-fdbe-4410-b33a-1ef30fba0b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+------------+\n",
            "|latitude|longitude|median_value|\n",
            "+--------+---------+------------+\n",
            "|   32.95|  -117.26|    500001.0|\n",
            "|   32.83|  -117.26|    500001.0|\n",
            "|   32.83|  -117.31|    500001.0|\n",
            "|   32.84|  -117.27|    500001.0|\n",
            "|   32.76|  -117.19|    500001.0|\n",
            "|   32.84|  -117.25|    500001.0|\n",
            "|   32.72|  -117.23|    500001.0|\n",
            "|   32.85|  -117.26|    500001.0|\n",
            "|   32.81|  -117.29|    500001.0|\n",
            "|   32.85|  -117.24|    500001.0|\n",
            "+--------+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Households with More Than 4 Persons Per Household\n",
        "result9_mithil = spark.sql(\"\"\"\n",
        "    SELECT COUNT(*) as large_households\n",
        "    FROM california_housing\n",
        "    WHERE population / households > 4\n",
        "\"\"\")\n",
        "result9_mithil.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_ysLY3XAMM9",
        "outputId": "cec5e185-9b03-4110-e486-739b2acc8056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|large_households|\n",
            "+----------------+\n",
            "|            1437|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Areas with the Highest House Density (Rooms per Area)\n",
        "result10_mithil = spark.sql(\"\"\"\n",
        "    SELECT latitude, longitude, (total_rooms / housing_median_age) as rooms_density\n",
        "    FROM california_housing\n",
        "    ORDER BY rooms_density DESC\n",
        "    LIMIT 10\n",
        "\"\"\")\n",
        "result10_mithil.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0znwk7ZAUFd",
        "outputId": "41b5a580-05b3-4023-db4d-a98e1f683150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-----------------+\n",
            "|latitude|longitude|    rooms_density|\n",
            "+--------+---------+-----------------+\n",
            "|   38.72|  -121.35|          10948.5|\n",
            "|   33.57|  -117.16|          10195.5|\n",
            "|   33.89|  -117.74|          9484.25|\n",
            "|   33.89|  -117.52|           8989.0|\n",
            "|   33.52|  -117.12|          7600.25|\n",
            "|    33.9|  -117.19|           7020.0|\n",
            "|   38.77|  -121.33|           6738.0|\n",
            "|    33.9|  -117.33|           6418.5|\n",
            "|   38.66|  -121.13|           6180.0|\n",
            "|   33.97|  -117.21|6118.666666666667|\n",
            "+--------+---------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop the Spark Session\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "t00yJGxyAY1d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}